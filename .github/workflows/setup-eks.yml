name: Setup EKS Infrastructure

on:
  workflow_dispatch:
    inputs:
      action:
        description: 'Action to perform'
        required: true
        default: 'setup'
        type: choice
        options:
          - setup
          - destroy
          - status

env:
  AWS_REGION: us-east-1
  EKS_CLUSTER_NAME: image-editor-cluster
  NAMESPACE: image-editor

jobs:
  setup-eks:
    name: Setup EKS Infrastructure
    runs-on: blacksmith-2vcpu-ubuntu-2404
    if: ${{ github.event.inputs.action == 'setup' }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: "1.5.0"

    - name: Terraform Init
      working-directory: ./terraform-demo/terraform
      run: terraform init

    - name: Terraform Plan
      working-directory: ./terraform-demo/terraform
      run: terraform plan -out=tfplan

    - name: Terraform Apply
      working-directory: ./terraform-demo/terraform
      run: terraform apply tfplan

    - name: Update kubeconfig
      run: |
        aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.EKS_CLUSTER_NAME }}
        kubectl cluster-info

    - name: Install Helm
      run: |
        curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
        helm version

    - name: Install AWS Load Balancer Controller
      run: |
        echo "üì¶ Installing AWS Load Balancer Controller..."
        
        # Add the EKS Helm chart repository
        helm repo add eks https://aws.github.io/eks-charts
        helm repo update
        
        # Get VPC ID
        VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=image-editor-vpc" --query "Vpcs[0].VpcId" --output text --region ${{ env.AWS_REGION }})
        
        # Get IAM role ARN from Terraform output
        cd terraform-demo/terraform
        IAM_ROLE_ARN=$(terraform output -raw aws_load_balancer_controller_role_arn)
        cd ../..
        
        # Create service account
        cat <<EOF | kubectl apply -f -
        apiVersion: v1
        kind: ServiceAccount
        metadata:
          labels:
            app.kubernetes.io/component: controller
            app.kubernetes.io/name: aws-load-balancer-controller
          name: aws-load-balancer-controller
          namespace: kube-system
          annotations:
            eks.amazonaws.com/role-arn: $IAM_ROLE_ARN
        EOF
        
        # Install the controller
        helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller \
          -n kube-system \
          --set clusterName=${{ env.EKS_CLUSTER_NAME }} \
          --set serviceAccount.create=false \
          --set serviceAccount.name=aws-load-balancer-controller \
          --set region=${{ env.AWS_REGION }} \
          --set vpcId=$VPC_ID \
          --wait
        
        # Verify installation
        kubectl get deployment -n kube-system aws-load-balancer-controller
        
        echo "‚úÖ AWS Load Balancer Controller installed successfully!"

    - name: Create Application Namespace
      run: |
        kubectl create namespace ${{ env.NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -
        kubectl get namespaces

    - name: Setup Complete
      run: |
        echo "‚úÖ EKS infrastructure setup complete!"
        echo ""
        echo "üìä Cluster Information:"
        kubectl get nodes
        echo ""
        echo "üéØ Next Steps:"
        echo "1. Run the 'Deploy to EKS' workflow to deploy the application"
        echo "2. Or manually deploy using: kubectl apply -f terraform-demo/k8s-manifests/"

  destroy-eks:
    name: Destroy EKS Infrastructure
    runs-on: blacksmith-2vcpu-ubuntu-2404
    if: ${{ github.event.inputs.action == 'destroy' }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Update kubeconfig
      run: |
        aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.EKS_CLUSTER_NAME }} || true

    - name: Delete Kubernetes Resources
      run: |
        echo "üóëÔ∏è Deleting Kubernetes resources..."
        
        # Delete ingress first (to remove ALB)
        kubectl delete ingress --all -n ${{ env.NAMESPACE }} --ignore-not-found || true
        
        # Wait for ALB to be deleted
        sleep 30
        
        # Delete namespace (will delete all resources within)
        kubectl delete namespace ${{ env.NAMESPACE }} --ignore-not-found || true
        
        # Uninstall AWS Load Balancer Controller
        helm uninstall aws-load-balancer-controller -n kube-system || true
        
        echo "‚úÖ Kubernetes resources deleted"

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: "1.5.0"

    - name: Terraform Init
      working-directory: ./terraform-demo/terraform
      run: terraform init

    - name: Terraform Destroy
      working-directory: ./terraform-demo/terraform
      run: terraform destroy -auto-approve

    - name: Cleanup Complete
      run: |
        echo "‚úÖ EKS infrastructure destroyed successfully!"

  status-check:
    name: Check EKS Status
    runs-on: blacksmith-2vcpu-ubuntu-2404
    if: ${{ github.event.inputs.action == 'status' }}
    
    steps:
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Check EKS Cluster
      run: |
        echo "üîç Checking EKS cluster status..."
        
        # Check if cluster exists
        if aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }} 2>/dev/null; then
          echo "‚úÖ EKS cluster exists"
          
          # Update kubeconfig
          aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.EKS_CLUSTER_NAME }}
          
          echo -e "\nüìä Cluster Information:"
          kubectl cluster-info
          
          echo -e "\nüñ•Ô∏è Nodes:"
          kubectl get nodes
          
          echo -e "\nüì¶ Namespaces:"
          kubectl get namespaces
          
          echo -e "\nüöÄ Deployments in ${{ env.NAMESPACE }}:"
          kubectl get deployments -n ${{ env.NAMESPACE }} 2>/dev/null || echo "Namespace not found"
          
          echo -e "\nüîå Services in ${{ env.NAMESPACE }}:"
          kubectl get services -n ${{ env.NAMESPACE }} 2>/dev/null || echo "Namespace not found"
          
          echo -e "\nüåê Ingress in ${{ env.NAMESPACE }}:"
          kubectl get ingress -n ${{ env.NAMESPACE }} 2>/dev/null || echo "Namespace not found"
          
          # Try to get ALB URL
          ALB_URL=$(kubectl get ingress -n ${{ env.NAMESPACE }} image-editor-ingress -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "")
          
          if [ -n "$ALB_URL" ]; then
            echo -e "\nüåê Application URL: http://$ALB_URL"
          fi
          
          echo -e "\nüéÆ AWS Load Balancer Controller:"
          kubectl get deployment -n kube-system aws-load-balancer-controller 2>/dev/null || echo "Not installed"
          
        else
          echo "‚ùå EKS cluster does not exist or is not accessible"
        fi